---
layout: post
title:  "Customer Sales Churn"
date:   2018-09-05 15:33:51 -0600
author: "Kenneth Hunt, MBA"
image: me3.JPG
---

![sc1]({{ "/assets/img/sc1.jpg" | absolute_url }})

Customer Churn, or customer attrition is a very signifcant metric for companies. It is much less expensive 
for most companies to retain their current customers than it is to go through many marketing steps in an effort to 
acquire new customers. Losing customers also affects future growth for companies. This is an area  where data science can help companies by setting up systems to predict which of a company's customers might by more likely to "churn" or leave the company. 

This is an analysis of a data set containing 6 variables, and 1000 observations. The response variable of this dataset
is “churn”, which describes whether a customer will leave the company based on the other variables which are “predictors”.
The other 5 variable in this dataset are "Tenure", "Age", "Income", "Education", and "Members."

## 'data.frame':    1000 obs. of  6 variables:
##  $ tenure : int  13 11 68 33 23 41 45 38 45 68 ...
##  $ age    : int  44 33 52 33 30 39 22 35 59 41 ...
##  $ income : int  64 136 116 33 30 78 19 76 166 72 ...
##  $ educ   : Factor w/ 5 levels  4 5 1 2 1 2 2 2 4 1 ...
##  $ members: Factor w/6 levels 2 6 2 1 4 1 5 3 5 3 ...
##  $ churn  : Factor w/ 2 levels "0","1": 2 2 1 2 1 1 2 1 1 1 ...

The first thing that I will look at in the dataset is that there is a class imbalance with the number of customers that are
churning "1" and the ones who are not churning "0."

![sc2]({{ "/assets/img/sc2.png" | absolute_url }})


As the graph above shows, there are approximately 73% more values in the "0" category than in the "1" category. It is possible this class imbalance will affect algorithms that may be used in a prediction. 

Here is a look at the correlation chart for all of the variables. We can see strong correlation between Age and Tenure. These variables seem to move together. 

![sc3]({{ "/assets/img/sc3.png" | absolute_url }})

I divided the dataset into approximately 70% for the training set, and 30% for the testing set. I built the predictive model using the random forest algorithm. 

The random forest algorithm is similar to the bagging algorithm in that a large number of training subsets are generated, and a separate tree is fit in each subset. In random forests, each tree uses a random sample of predictors at every splitting node. So all predictors are not used in each tree.

The number of predictors used in every splitting node is computed as follows:

*The number for regression trees is the half of the total number of predictors.

*The number for classification trees is approximately the square root of the total number of predictors.

I am using the classification method here since the churn variable is the response variable. 

Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 186  44
         1  35  32
                                          
               Accuracy : 0.734           
                 95% CI : (0.6799, 0.7834)
    No Information Rate : 0.7441          
    P-Value [Acc > NIR] : 0.6822          
                                          
                  Kappa : 0.2733          
 Mcnemar's Test P-Value : 0.3681          
                                          
            Sensitivity : 0.4211          
            Specificity : 0.8416          
         Pos Pred Value : 0.4776          
         Neg Pred Value : 0.8087          
             Prevalence : 0.2559          
         Detection Rate : 0.1077          
   Detection Prevalence : 0.2256          
      Balanced Accuracy : 0.6313          
                                          
       'Positive' Class : 1   


The random forest model had an overall accuracy of 73.4%.This amount is somewhat misleading because it also has a sensitivity rate of 42% and a specificity rate of 84%. this means that the model predicts the "0" values much better at 84% than it does the customers that are likely to churn at 42%. The reason for this is the class imbalance; there are more non-churning customers than churning customers. One way to improve this is to use "oversampling" or "undersampling" to balance out the variables. 

Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 124  17
         1  97  59
                                          
               Accuracy : 0.6162          
                 95% CI : (0.5582, 0.6717)
    No Information Rate : 0.7441          
    P-Value [Acc > NIR] : 1               
                                          
                  Kappa : 0.2508          
 Mcnemar's Test P-Value : 1.372e-13       
                                          
            Sensitivity : 0.7763          
            Specificity : 0.5611          
         Pos Pred Value : 0.3782          
         Neg Pred Value : 0.8794          
             Prevalence : 0.2559          
         Detection Rate : 0.1987          
   Detection Prevalence : 0.5253          
      Balanced Accuracy : 0.6687          
                                          
       'Positive' Class : 1

For this dataset, using the "undersampling" method, I was able to produce the highest sensitivity rate of 77.63% 

This is a great example of using the random forest algorithm to predict a customer churn rate of 77.63%. With new data such as similar information from a current customer, a more reliable method for predicting whether a customer is likely to leave can be developed. 

This is a method for any company to begin to take steps to prevent losing customers, which will affect profitability. 















<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-125151167-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-125151167-1');
</script>











References:
https://rpubs.com/kennethbhunt/397212





 





