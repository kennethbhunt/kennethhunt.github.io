---
layout: post
title:  "Customer Sales Churn"
date:   2018-09-05 15:33:51 -0600
author: "Kenneth Hunt, MBA"
image: me3.JPG
---

![sc1]({{ "/assets/img/sc1.jpg" | absolute_url }})

Customer Churn, or customer attrition is a very signifcant metric for companies. it is much less expensive 
for most companies to retain their current customers than it is to go through many marketing steps in an effort to 
acquire new customers. Losing companies also affects future growth for companies. This is an area  where data science can help companies by setting up systems to predict which of a company's customers might by more likely to "churn" or leave the company. 

This is an analysis of a data set containing 6 variables, and 1000 observations. The response variable of this dataset
is “churn”, which describes whether a customer will leave the company based on the other variables which are “predictors”.
The other 5 variable in this dataset are "Tenure", "Age", "Income", "Education", and "Members."

The first thing that I will look at in the dataset is that there is a class imbalance with the number of customers that are
churning "1" and the one who are not churning "0."

![sc2]({{ "/assets/img/sc2.png" | absolute_url }})


As the graph above shows, there are approximately 73% more values in the "0" category than in the "1" category. It is possible this class imbalance will affect algorithms that may be used in a prediction. 

Here is a look at the correlation chart for all of the variables. We can see strong correlation between Age and Tenure. These variables seem to move together. 

![sc3]({{ "/assets/img/sc3.png" | absolute_url }})

I divided the dataset into approximately 70% for the training set, and 30% for the testing set. I built the predictive model using the random forest algorithm. 

The random forests technique is similar to bagging: a big number of training subsets are generated, and a separate tree is fit in each subset. In random forests, each tree uses a random sample of predictors at every splitting node. So all predictors are not used in each tree.

The number of predictors used in every splitting node is computed as follows:
*for the regression trees it is the half of the total number of predictors
*for the classification trees it is approximately the square root of the total number of predictors.

I am using the classification method since the churn variable is the response variable. 















<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-125151167-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-125151167-1');
</script>











References:
Sean J. Taylor∗
†
Facebook, Menlo Park, California, United States
sjt@fb.com
and
Benjamin Letham†
Facebook, Menlo Park, California, United States
bletham@fb.com
https://peerj.com/preprints/3190/
https://facebook.github.io/prophet/docs/quick_start.html#r-api
https://facebook.github.io/prophet/





 





